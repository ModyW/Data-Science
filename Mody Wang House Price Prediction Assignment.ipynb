{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pycaret as pc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.regression import * \n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "import pylab as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\Mo Di Wang\\\\Desktop\\\\Queen's University MFIT\\\\MMA867\\\\Assignment 1\\\\train.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\Mo Di Wang\\\\Desktop\\\\Queen's University MFIT\\\\MMA867\\\\Assignment 1\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_box= train_data.select_dtypes(['int64'])\n",
    "column_box = train_data_box.columns.tolist()\n",
    " \n",
    "fig = plt.figure(figsize=(15, 53))\n",
    "for col in column_box:\n",
    "    ax = fig.add_subplot(15,4, column_box.index(col)+1)\n",
    "    train_data[col].plot.box()\n",
    "    plt.title('Box Plot For ' + col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_box= train_data.select_dtypes(['float64'])\n",
    "column_box = train_data_box.columns.tolist()\n",
    " \n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "for col in column_box:\n",
    "    ax = fig.add_subplot(7, 8, column_box.index(col)+1)\n",
    "    train_data[col].plot.box()\n",
    "    plt.title('Box Plot For ' + col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Missing_Count = train_data.isnull().sum()\n",
    "Total_Count = train_data.isnull().count()\n",
    "Missing_Percent = Missing_Count/Total_Count\n",
    "Missing_Data = pd.concat([Missing_Count,Missing_Percent], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(25, 'Missing Percent')\n",
    "print(Missing_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_Count2 = test_data.isnull().sum()\n",
    "Total_Count2 = test_data.isnull().count()\n",
    "Missing_Percent2 = Missing_Count2/Total_Count2\n",
    "Missing_Data2 = pd.concat([Missing_Count2,Missing_Percent2], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(25, 'Missing Percent')\n",
    "print(Missing_Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured =train_data.drop(['Id','PoolQC','MiscFeature','Alley','Fence'],axis = 1)\n",
    "test_data_featured = test_data.drop(['Id','PoolQC','MiscFeature','Alley','Fence'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_Count3 = train_data_featured.isnull().sum()\n",
    "Total_Count3 = train_data_featured.isnull().count()\n",
    "Missing_Percent3 = Missing_Count3/Total_Count3\n",
    "Missing_Data3 = pd.concat([Missing_Count3,Missing_Percent3], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(25, 'Missing Percent')\n",
    "print(Missing_Data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_cateo = train_data_featured.select_dtypes(['object'])\n",
    "Missing_Count4 = train_data_featured_cateo.isnull().sum()\n",
    "Total_Count4 = train_data_featured_cateo.isnull().count()\n",
    "Missing_Percent4 = Missing_Count4/Total_Count4\n",
    "Missing_Data4 = pd.concat([Missing_Count4,Missing_Percent4], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(15, 'Missing Percent')\n",
    "cateo = Missing_Data4[Missing_Data4[Missing_Data4.columns[1]]>0].index.tolist()\n",
    "for i in cateo:\n",
    "    print(train_data_featured[i].value_counts())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_featured_cateo = test_data_featured.select_dtypes(['object'])\n",
    "Missing_Count7 = test_data_featured_cateo.isnull().sum()\n",
    "Total_Count7 = test_data_featured_cateo.isnull().count()\n",
    "Missing_Percent7 = Missing_Count7/Total_Count7\n",
    "Missing_Data7 = pd.concat([Missing_Count7,Missing_Percent7], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(15, 'Missing Percent')\n",
    "cateo = Missing_Data7[Missing_Data7[Missing_Data7.columns[1]]>0].index.tolist()\n",
    "for i in cateo:\n",
    "    print(test_data_featured[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_bar_plot = train_data_featured.select_dtypes(['object'])\n",
    "column_box = train_data_featured_bar_plot.columns.tolist()\n",
    "fig = plt.figure(figsize=(27, 27))\n",
    "for i in column_box:\n",
    "    ax = fig.add_subplot(15,7, column_box.index(i)+1)\n",
    "    train_data_featured[i].value_counts().plot(kind='bar')\n",
    "    plt.title('Bar Plot For ' + i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('FireplaceQu','GarageFinish','GarageQual','GarageCond','GarageType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MasVnrType'):\n",
    "    train_data_featured[i].fillna('None',inplace = True)\n",
    "for k in ('FireplaceQu','GarageFinish','GarageQual','GarageCond','GarageType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MasVnrType'):\n",
    "    test_data_featured[k].fillna('None',inplace = True)\n",
    "    \n",
    "train_data_featured['Electrical'].fillna('SBrkr', inplace =True) \n",
    "test_data_featured['MSZoning'].fillna('RL', inplace =True)\n",
    "test_data_featured['Functional'].fillna('Typ', inplace =True) \n",
    "test_data_featured['Utilities'].fillna('AllPub', inplace =True)  \n",
    "test_data_featured['Exterior2nd'].fillna('VinylSd', inplace =True) \n",
    "test_data_featured['KitchenQual'].fillna('TA', inplace =True) \n",
    "test_data_featured['SaleType'].fillna('WD', inplace =True)\n",
    "test_data_featured['Exterior1st'].fillna('VinylSd', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_Count5 = train_data_featured.isnull().sum()\n",
    "Total_Count5 = train_data_featured.isnull().count()\n",
    "Missing_Percent5 = Missing_Count5/Total_Count5\n",
    "Missing_Data5 = pd.concat([Missing_Count5,Missing_Percent5], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(25, 'Missing Percent')\n",
    "print(Missing_Data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_Count6 = test_data_featured.isnull().sum()\n",
    "Total_Count6 = test_data_featured.isnull().count()\n",
    "Missing_Percent6 = Missing_Count6/Total_Count6\n",
    "Missing_Data6 = pd.concat([Missing_Count6,Missing_Percent6], axis=1, keys = [\"Missing Count\",\"Missing Percent\"]).sort_values('Missing Percent', ascending=False).nlargest(25, 'Missing Percent')\n",
    "print(Missing_Data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sales Price Distribution Plot\n",
    "sns.set_style(\"white\")\n",
    "sns.distplot(train_data_featured['SalePrice'],fit = norm);\n",
    "(mean, sd) = norm.fit(train_data_featured['SalePrice'])\n",
    "plt.legend(['$\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mean, sd)])\n",
    "plt.title('Sale Price Distribution Plot');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sales price QQ Plot\n",
    "fig = plt.figure()\n",
    "stats.probplot(train_data_featured['SalePrice'], dist=\"norm\", plot=py)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis = train_data_featured['SalePrice'].kurtosis()\n",
    "skewness = train_data_featured['SalePrice'].skew()\n",
    "print('Kurtorsis for the Sales price is {}'.format(kurtosis))\n",
    "print('Skewness for the Sales price is {}'.format(skewness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured['LogSalePrice'] = np.log(train_data_featured['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_featured[\"LogSalePrice\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis = train_data_featured['LogSalePrice'].kurtosis()\n",
    "skewness = train_data_featured['LogSalePrice'].skew()\n",
    "print('Kurtorsis for the Sales price is {}'.format(kurtosis))\n",
    "print('Skewness for the Sales price is {}'.format(skewness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Sales Price Distribution\n",
    "sns.set_style(\"white\")\n",
    "sns.distplot(train_data_featured['LogSalePrice'],fit = norm);\n",
    "(mean, sd) = norm.fit(train_data_featured['LogSalePrice'])\n",
    "plt.legend(['$\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mean, sd)])\n",
    "plt.title('Log Sale Price Distribution Plot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QQ-plot Log Sale Price\n",
    "fig = plt.figure()\n",
    "stats.probplot(train_data_featured['LogSalePrice'], dist=\"norm\", plot=py)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis = train_data_featured['LogSalePrice'].kurtosis()\n",
    "skewness = train_data_featured['LogSalePrice'].skew()\n",
    "print('Kurtorsis for the Log Sales price is {}'.format(kurtosis))\n",
    "print('Skewness for the Log Sales price is {}'.format(skewness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured[\"TotalFL\"] =train_data_featured[\"TotalBsmtSF\"] +  train_data_featured[\"GrLivArea\"]\n",
    "test_data_featured[\"TotalFL\"] =test_data_featured[\"TotalBsmtSF\"] +  test_data_featured[\"GrLivArea\"]\n",
    "train_data_featured[\"BsmtBath\"] = train_data_featured[\"BsmtFullBath\"] +  train_data_featured[\"BsmtHalfBath\"]\n",
    "test_data_featured[\"BsmtBath\"] = test_data_featured[\"BsmtFullBath\"] +  test_data_featured[\"BsmtHalfBath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_table = train_data_featured.corr().abs()\n",
    "\n",
    "top_corr = (correlation_table.where(np.triu(np.ones(correlation_table.shape), k=1).astype(np.bool))\n",
    "                  .stack()\n",
    "                  .sort_values(ascending=False))\n",
    "\n",
    "print(top_corr.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_Table2 = train_data_featured.corr()\n",
    "correlation_filter= correlation_Table2[((correlation_Table2 >= 0.67) | (correlation_Table2 <= -0.67))]\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(correlation_filter, annot=True, cmap=\"Reds\")\n",
    "plt.title('Correlation Heatmap',fontsize=30);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured.drop(['SalePrice','BsmtBath','GarageCars','GrLivArea','GarageYrBlt','1stFlrSF','TotalBsmtSF','TotRmsAbvGrd','2ndFlrSF'],axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the variables which have correlaiton with the Log Sales Price before removing outliers.\n",
    "corr = train_data_featured.corr()\n",
    "high_corr = corr['LogSalePrice'].sort_values(ascending=False)[1:][:13].index.tolist()\n",
    "fig, axes = plt.subplots(4,3, figsize=(20, 10), sharey=True);\n",
    "plt.subplots_adjust(hspace = 0.7, wspace=0.1)\n",
    "fig.suptitle('Highest Correlation with Log Sale Price Before Removing Outliers', fontsize=20);\n",
    "for i,col in zip(range(12),high_corr):\n",
    "    sns.scatterplot(y=train_data_featured['LogSalePrice'], x=train_data_featured[col], ax=axes[i//3][i%3])\n",
    "    axes[i//3][i%3].set_title('Log Sales Price with '+col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers from the graphs\n",
    "drop_index = train_data_featured[((train_data_featured['TotalFL']>8000) & (train_data_featured['LogSalePrice']<13))|\n",
    "                  ((train_data_featured['LotFrontage']>300) & (train_data_featured['LogSalePrice']<16))|\n",
    "                  ((train_data_featured['BsmtFinSF1']>5000) & (train_data_featured['LogSalePrice']<13))|\n",
    "                  ((train_data_featured['MasVnrArea']>1200) & (train_data_featured['LogSalePrice']<16))].index\n",
    "\n",
    "train_data_featured = train_data_featured.drop(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the variables which have correlaiton with the Log Sales Price before after removing outliers.\n",
    "corr = train_data_featured.corr()\n",
    "high_corr = corr['LogSalePrice'].sort_values(ascending=False)[1:][:13].index.tolist()\n",
    "fig, axes = plt.subplots(4,3, figsize=(20, 10), sharey=True);\n",
    "plt.subplots_adjust(hspace = 0.7, wspace=0.1)\n",
    "fig.suptitle('Highest Correlation with Log Sale Price After Removing Outliers', fontsize=20);\n",
    "for i,col in zip(range(12),high_corr):\n",
    "    sns.scatterplot(y=train_data_featured['LogSalePrice'], x=train_data_featured[col], ax=axes[i//3][i%3])\n",
    "    axes[i//3][i%3].set_title('Log Sales Price with '+col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_distribution = train_data_featured.select_dtypes(['float64','int64'])\n",
    "numeric_cols = train_data_featured_distribution.columns.tolist()\n",
    " \n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "for col in numeric_cols:\n",
    "    ax = fig.add_subplot(7, 8, numeric_cols.index(col)+1)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.hist(train_data_featured_distribution[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_qq = train_data_featured.select_dtypes(['float64','int64'])\n",
    "column_list = train_data_featured_qq.columns.tolist()\n",
    " \n",
    "fig = plt.figure(figsize=(35, 35))\n",
    "for col in column_list:\n",
    "    ax = fig.add_subplot(7, 8, numeric_cols.index(col)+1)\n",
    "    ax.set_xlabel(col)\n",
    "    stats.probplot(train_data_featured_qq[col], dist=\"norm\", plot=py)\n",
    "    plt.title('QQ Plot For ' + col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_SK_KR = train_data_featured.select_dtypes(['float64','int64'])\n",
    "train_data_featured_SK_KR.drop(['LogSalePrice'],axis=1, inplace=True) \n",
    "column_list = train_data_featured_SK_KR.columns.tolist()\n",
    "\n",
    "dataset_SK_KR = pd.DataFrame(columns = ['Variable', 'Skewness', \"Kurtosis\"])\n",
    "for col in column_list:\n",
    "    dataset_SK_KR = dataset_SK_KR.append({'Variable': col,'Skewness': train_data_featured_SK_KR[col].skew(),'Kurtosis': train_data_featured_SK_KR[col].kurtosis()}, ignore_index=True)\n",
    "\n",
    "\n",
    "dataset_SK_KR.sort_values('Skewness', ascending=False).nlargest(25, 'Skewness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_cols = dataset_SK_KR[dataset_SK_KR['Skewness'].abs()>0.3].index.tolist()\n",
    "dataset_SK_KR2 = pd.DataFrame(columns = ['Variable'])\n",
    "for col in skew_cols:\n",
    "    dataset_SK_KR2 = dataset_SK_KR2.append({'Variable': train_data_featured_SK_KR.columns[col]}, ignore_index=True)\n",
    "dataset_SK_KR2\n",
    "for col in range(len(dataset_SK_KR2)):\n",
    "    train_data_featured[dataset_SK_KR2[dataset_SK_KR2.columns[0]].iloc[col]] = np.log(train_data_featured[dataset_SK_KR2[dataset_SK_KR2.columns[0]].iloc[col]])\n",
    "    test_data_featured[dataset_SK_KR2[dataset_SK_KR2.columns[0]].iloc[col]] = np.log(test_data_featured[dataset_SK_KR2[dataset_SK_KR2.columns[0]].iloc[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_qq = train_data_featured.select_dtypes(['float64','int64'])\n",
    "column_list = train_data_featured_qq.columns.tolist()\n",
    " \n",
    "fig = plt.figure(figsize=(35, 35))\n",
    "for col in column_list:\n",
    "    ax = fig.add_subplot(7, 8, numeric_cols.index(col)+1)\n",
    "    ax.set_xlabel(col)\n",
    "    stats.probplot(train_data_featured_qq[col], dist=\"norm\", plot=py)\n",
    "    plt.title('QQ Plot For ' + col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_featured_SK_KR = train_data_featured.select_dtypes(['float64','int64'])\n",
    "train_data_featured_SK_KR.drop(['LogSalePrice'],axis=1, inplace=True) \n",
    "column_list = train_data_featured_SK_KR.columns.tolist()\n",
    "\n",
    "dataset_SK_KR = pd.DataFrame(columns = ['Variable', 'Skewness', \"Kurtosis\"])\n",
    "for col in column_list:\n",
    "    dataset_SK_KR = dataset_SK_KR.append({'Variable': col,'Skewness': train_data_featured_SK_KR[col].skew(),'Kurtosis': train_data_featured_SK_KR[col].kurtosis()}, ignore_index=True)\n",
    "\n",
    "\n",
    "dataset_SK_KR.sort_values('Skewness', ascending=False).nlargest(15, 'Skewness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = setup(data = train_data_featured, target = 'LogSalePrice',normalize = True, train_size = 0.8,session_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models(n_select = 3, sort = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge = create_model('ridge')\n",
    "Ridge_Tuned = tune_model(Ridge, optimize = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge = finalize_model(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_holdout = predict_model(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(Ridge,data = test_data_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['Label'] = np.exp(predictions['Label'])\n",
    "print(predictions['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.concat([test_data['Id'],predictions['Label']], axis=1)\n",
    "prediction =prediction.rename(columns = {'Label':'SalePrice'})\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('Submission.csv',index = False)\n",
    "print(prediction.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sales Price Distribution Plot\n",
    "sns.set_style(\"white\")\n",
    "sns.distplot(prediction['SalePrice'],fit = norm);\n",
    "(mean, sd) = norm.fit(prediction['SalePrice'])\n",
    "plt.legend(['$\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mean, sd)])\n",
    "plt.title('Predicted Sale Price Distribution Plot');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
